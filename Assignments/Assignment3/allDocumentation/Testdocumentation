For our tests, we used some automatically generated programs and some manually
created programs.

100 semantically correct programs were generated.
100 semantically incorrect programs were generated.
Other semantically incorrect programs were generated to test each semantic
checking rule individually.

We generated automatically programs by first formalizing the semantics
in Agda. Then this was converted to Prolog to take advantage of the
backtracking features. Failing programs were generated by changing the
rules.

Automatically generated programs can be found in tests/passing/anthony and
tests/failing/anthony

Index of manually generated failing programs to test each rule:
files can be found in tests/failing/felix

S30-andor-boolean.488
S30-exit-when-boolean.488
S30-if-boolean.488
S30-not-boolean.488
S31-arithmetic.488
S31-array.488
S31-comp.488
S31-get-input.488
S32-type-equality.488
S34-assignment-type.488
S35-return-type.488
S36-argument-type.488
S37-declaration.488
S38-declaration.488
S39-param-declaration.488
S40-function-declaration.488
S41-proc-declaration.488
S42-noparams.488
S43-numargs.488
S50-exit-outside-loop.488
S51-return-outside-function.488
S52-return-outside-procedure.488
S53-function-without-return.488

Tests focusing on type-checking based on these rules
S10.488
S11.488
S12.488
S13.488
S14.488
S15.488
S16.488
S17.488
S18.488
S19.488
